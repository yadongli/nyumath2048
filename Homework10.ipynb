{
 "metadata": {
  "name": "",
  "signature": "sha256:c44228980d83dcfd43a11362413aeb84b8ed535a7c48c7925ca4cb9a218a0d99"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Homework Set 10"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline\n",
      "import pandas as pd\n",
      "\n",
      "import fmt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING: pylab import has clobbered these variables: ['norm', 'e']\n",
        "`%matplotlib` prevents importing * from pylab and numpy\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Problem 1\n",
      "\n",
      "Use the dual objective discussed in class to solve the following maximum entropy optimization problems.\n",
      "\n",
      "Find the the maximum entropy (ME) distribution without any prior distributions (equivalent to uniform priors) with the following constraints:\n",
      "\n",
      "1. with constraints of $\\mathbb{E}[x] = 0$ and $\\mathbb{E}[x^2] = 1$; show that the resulting distribution is indeed normal.\n",
      "2. does your ME distribution from #1 depend on the range of the discrete samples? for example, do the resulting ME distribution look normal if the discrete samples span only [-1.5, 1.5]? explain why.\n",
      "3. define a transformation of $y = e^x$, where $y$ is a lognormal distribution if $x$ is normal. Solve the ME problem using equal spaced samples in $y$ with the constraint $\\mathbb{E}[\\log(y)]=0$ and $\\mathbb{E}[\\log^2(y)] = 1$, and check if the resulting $y$ distribution is lognormal (it is not). \n",
      "4. Explain why your step 3 do not result in a lognormal distribution.\n",
      "5. [optional] Can you adjust the prior distribution in #3 to reproduce the similar results as in #1 without changing the equal-spaced sampling in $y$?\n",
      "\n",
      "Hint: \n",
      "* this problem illustrate that the importance of the prior distributions.\n",
      "* You can use the me package as part of the class library to solve this problem. You will get extra credit if you can implement your own version of the ME optimizations. If you choose to implement your own, beware that the exp() function may overflow, so you need to apply a cap before calling exp().\n",
      "* for #1. you should try a discretization of a wide range first, for example (-6, 6) with small sampling steps\n",
      "* the Q-Q plot is an effective way to show whether two distributions are similar. Google search Q-Q plot if you don't know what it is."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Problem 2\n",
      "\n",
      "Often times, we run into conflicting constraints in practice, \n",
      "\n",
      "1. try to solve the ME optimization with standard normal as the prior distribution, with the following conflicting skewness constraints of $E[x^3] = -2$ and $E[x^3] = 2$.  Show that the numerical optimizer will fail to find a solution if we don't allow error bounds (ie, like the bid/ask discussed in class); check your implementation so that it fails gracefully (i.e., it should not stop from running the rest of your ipython notebook cells when \"Run All\").\n",
      "2. show that you can find a solution by introducing error bounds, and shift the distribution to skew left or right by adjusting the error bounds related to these donstraints.\n",
      "\n",
      "This exercise illustrates that error bounds improve the robustness of the ME method."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Problem 3\n",
      "\n",
      "[open question] The asset allocation problem could be formulated as a maximum entropy optimization problem, if we view the dollar value of asset allocation as a distribution. Please give your thoughts on whether maximum entropy is a sensible objective function for solving the asset allocation problem. \n",
      "\n",
      "Hint: compare maximum entropy with the standard mean/variance method of asset allocation. Please give very short and concise answers. (this question can be anwsered in no more than 2 sentences)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Problem 4\n",
      "\n",
      "A classic problem of Shapley allocation is the glove game, where three players A, B, C each has a single glove of left, left and right hand. Assuming that one pair of gloves with left and right hand worth $1, and unpaired gloves are worthless. \n",
      "\n",
      "1. apply Shapley allocation to divide the $1 total value among the three players, by listing all possible permutations and take the average.\n",
      "2. can you compute the stand-alone or Euler allocation for this game?\n",
      "3. suppose B and C belongs to the same team, and A belongs to a different team, compute the allocation between two teams of [A] and [BC] using both Shapley and Constrained Shapley; comment on which allocation gives more sensible results. \n",
      "\n",
      "Hint: since the number of players are small, you can enumerate all possible permutations."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}